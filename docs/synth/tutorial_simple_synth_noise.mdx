---
title: ホワイトノイズ発生器を作る
sidebar_position: 1
---

import CaptionImage from "@site/src/components/CaptionImage";
import SourcePageLink from "@site/src/components/SourcePageLink";

# チュートリアルホワイトノイズ・ジェネレーターを作る

このチュートリアルでは、簡単な合成とオーディオ出力を紹介します。このチュートリアルは、JUCE のオーディオ・アプリケーション（およびプラグイン）のコンセプトを理解するための鍵となります。

レベル Intermediate

プラットフォーム Windows, macOS, Linux

クラス： [オーディオコンポーネント](https://docs.juce.com/master/classAudioAppComponent "A base class for writing audio apps that stream from the audio i/o devices."), [オーディオソースチャンネル情報](https://docs.juce.com/master/structAudioSourceChannelInfo "Used by AudioSource::getNextAudioBlock()."), [オーディオバッファ](https://docs.juce.com/master/classAudioBuffer "A multi-channel buffer containing floating point audio samples."), [ランダム](https://docs.juce.com/master/classRandom "A random number generator.")

## はじめる

Download the demo project for this tutorial here: [ピップ](/tutorials/PIPs/SimpleSynthNoiseTutorial.zip) | [ジップ](/tutorials/ZIPs/SimpleSynthNoiseTutorial.zip). Unzip the project and open the first header file in the Projucer.

If you need help with this step, see [チュートリアルProjucerパート1：Projucerを始める](../tutorial_new_projucer_project/).

This tutorial assumes that you are familiar with the basic principles of digital audio. In particular, you should know how audio signals are represented using sampling. You should also be familiar with the idea of the *サンプルレート* in this context (which you may know as *サンプリングレート*, *サンプリング周波数*, or other similar terms).

# The demo project

The demo project was created using [プロジューサー](https://juce.com/projucer) **オーディオアプリケーション** template.

<CaptionImage src="https://docs.juce.com/master/tutorial_simple_synth_noise_screenshot1.png" caption="The Audio Application template shown highlighted within The Projucer." />


これは、JUCEで独自のオーディオ・アプリケーションを開発するための出発点として役立ちます。このデモプロジェクトは、ホワイトノイズを合成し、ターゲットデバイスのデフォルトのオーディオハードウェアから再生します。

# The Audio Application template

このチュートリアルでは、オーディオ出力のみを実装しています。オーディオ入力とオーディオ入力データのリアルタイムオーディオ処理については、他のチュートリアルで説明します。オーディオ・アプリケーション・テンプレートは、GUIアプリケーション・テンプレートとよく似ています：

-   The `メインコンテンツコンポーネント` class inherits from the [オーディオコンポーネント](https://docs.juce.com/master/classAudioAppComponent "A base class for writing audio apps that stream from the audio i/o devices.") class rather than the [コンポーネント](https://docs.juce.com/master/classComponent "The base class for all JUCE user-interface objects.") class.
-   The `juce_audio_utils` module is added to the project, in addition to the other audio-related modules that are added to projects by default.

Audio Application テンプレートは、ここで提供する例のような単純なアプリケーションに使用できます。また、より複雑なアプリケーション、基本的にはターゲットデバイスのオーディオハードウェアと直接対話する必要のあるアプリケーションにも拡張可能です。JUCEによるオーディオ・プラグインの作成については、他のチュートリアルで説明します。

## The audio application lifecycle

The [オーディオコンポーネント](https://docs.juce.com/master/classAudioAppComponent "A base class for writing audio apps that stream from the audio i/o devices.") class is an abstract base class, it has three [ピュアバーチャル](http://www.learncpp.com/cpp-tutorial/126-pure-virtual-functions-abstract-base-classes-and-interface-classes/) functions that represent the lifecycle of our audio application that we *マスト* implement in our derived class:

-   [AudioAppComponent::prepareToPlay()](classAudioAppComponent.html#a70634aa3ffaf6e7ff0d233e5933a063d "Tells the source to prepare for playing."): This is called just before audio processing starts.
-   [AudioAppComponent::releaseResources()](classAudioAppComponent.html#a588d9b990fc308774215548959e0fc50 "Allows the source to release anything it no longer needs after playback has stopped."): This is called when audio processing has finished.
-   [AudioAppComponent::getNextAudioBlock()](classAudioAppComponent.html#aec5e36e694a5bd2edae903d1079166b1 "Called repeatedly to fetch subsequent blocks of audio data."): This is called each time the audio hardware needs a new block of audio data.

Of these three, the most important is perhaps [AudioAppComponent::getNextAudioBlock()](classAudioAppComponent.html#aec5e36e694a5bd2edae903d1079166b1 "Called repeatedly to fetch subsequent blocks of audio data."), since this is where you will either generate or process audio in your JUCE audio application. To understand how this works, we need to know a little about how modern computers generate audio. The audio hardware needs to generate a certain number of samples per channel for each second of audio. The CD-quality sample rate is 44.1kHz, which means there needs to be 44100 samples per second per channel sent to the audio hardware for playback. Rather than being passed to the audio hardware a single sample at a time, the samples are passed in buffers — or blocks — containing a certain number of samples. For example, at 44.1kHz and a block size of 441 our [AudioAppComponent::getNextAudioBlock()](classAudioAppComponent.html#aec5e36e694a5bd2edae903d1079166b1 "Called repeatedly to fetch subsequent blocks of audio data.") function would be called 100 times per second.

:::note

The buffer size of 441 samples, above, is used to keep the arithmetic simple for the purposes of explanation. In practice, a buffer size of 441 would be unusual. Hardware buffer sizes would almost certainly be a even number and would tend to be powers-of-two (256, 512, 1024, and so on). It is important that your application is prepared to deal with *いずれも* buffer size. For more information on the settings for sample rate and buffer sizes, see [チュートリアルAudioDeviceManagerクラス](../tutorial_audio_device_manager/).

:::

Essentially, our [AudioAppComponent::getNextAudioBlock()](classAudioAppComponent.html#aec5e36e694a5bd2edae903d1079166b1 "Called repeatedly to fetch subsequent blocks of audio data.") is servicing the *オーディオ・コールバック* of the audio hardware. It is important to note that this function will be called from another thread (the *オーディオスレッド* in most cases).

JUCEオーディオ・アプリケーションが正しく動作するためには、さらに2つの重要な関数があります。今回は、それらを実装するのではなく、呼び出す必要があります：

-   [AudioAppComponent::setAudioChannels()](classAudioAppComponent.html#a1cb6b457848fa80df7efc39cf095d465 "A subclass should call this from their constructor, to set up the audio."): We must call this to register the number of input and output channels we need. Typically, we do this in our constructor. In turn, this function triggers the start of audio processing in our application.
-   [AudioAppComponent::shutdownAudio()](classAudioAppComponent.html#a40f1e657f048d02c5d065de566a84d92 "Shuts down the audio device and clears the audio source."): We must call this to shutdown the audio system. Typically, we do this in our destructor.

## Initialising the audio application

Let's now explore our simple implementation of a noise generator by examining the life cycle of an audio application in more detail. Our constructor needs to set up the size of the [コンポーネント](https://docs.juce.com/master/classComponent "The base class for all JUCE user-interface objects.") object (see [チュートリアルメイン・コンポーネント](../tutorial_main_component/)). We also need to initialise at least one audio output:

```
MainContentComponent()
    {
        setSize (800, 600)；
        setAudioChannels (0, 2); // 入力なし、出力2つ
    }
```

As mentioned above, the call to the [AudioAppComponent::setAudioChannels()](classAudioAppComponent.html#a1cb6b457848fa80df7efc39cf095d465 "A subclass should call this from their constructor, to set up the audio.") function triggers the audio system to start up. In particular, it will call the `prepareToPlay()` function:

```
void prepareToPlay (int samplesPerBlockExpected, double sampleRate) override
    {
        juce::String message；
        message << "再生準備中です；
        message << " samplesPerBlockExpected = " << samplesPerBlockExpected << " \n"；
        message << " sampleRate = " << sampleRate；
        juce::Logger::getCurrentLogger()->writeToLog (message)；
    }
```

In this case we don't really need to do anything here, but as it is a [ピュアバーチャル](http://www.learncpp.com/cpp-tutorial/126-pure-virtual-functions-abstract-base-classes-and-interface-classes/) function we *マスト* implement at least an empty function. Here we log some useful information that we can gain about the audio system on the target device at this point. The `期待されるサンプル数` argument, as its name suggests, is the size (in samples) of the buffers of audio that we can expect to be asked for each time a buffer of audio is requested in our `getNextAudioBlock()` function. This buffer size might vary between callbacks, but it is a good indication. The `サンプルレート` argument tells us the current sample rate of the hardware. We would need this if we were doing something that is frequency-dependent, such as synthesising tones (see [チュートリアルサイン波シンセサイザーを作る](../tutorial_sine_synth/)) or using equalisation. We would also need to know the sample rate if we were using delay effects. We don't need this information to generate noise.

## Generating audio data

Soon after this call to our `prepareToPlay()` function the audio thread will begin requesting blocks of audio via the [AudioAppComponent::getNextAudioBlock()](classAudioAppComponent.html#aec5e36e694a5bd2edae903d1079166b1 "Called repeatedly to fetch subsequent blocks of audio data.") function. This function is passed a single `バッファートゥフィル` argument that is an [オーディオソースチャンネル情報](https://docs.juce.com/master/structAudioSourceChannelInfo "Used by AudioSource::getNextAudioBlock().") struct. The [オーディオソースチャンネル情報](https://docs.juce.com/master/structAudioSourceChannelInfo "Used by AudioSource::getNextAudioBlock().") struct contains a multichannel buffer of audio samples. It also contains two integer values that specify which region of this buffer should be processed on this call. In more detail, the [オーディオソースチャンネル情報](https://docs.juce.com/master/structAudioSourceChannelInfo "Used by AudioSource::getNextAudioBlock().") contains the following members:

-   `オーディオサンプルバッファ*バッファ`: An AudioSampleBuffer object is a multichannel buffer of audio data that is essentially a multidimensional array of `フロート` values. When our `getNextAudioBlock()` function is called, this buffer contains any audio data from the target device's audio input (if we requested audio input). When our `getNextAudioBlock()` function returns, we must have filled the relevant section of the buffer with audio that we want to play.
-   `int startSample`: This is the sample index within the buffer where our `getNextAudioBlock()` function should start reading or writing audio.
-   `int numSamples`: This is the number of samples in the buffer that should be read or written.

浮動小数点値として保存されるオーディオデータは、非常に簡単です。オーディオ信号の各サンプルは、公称±1.0の範囲の値として保存されます。

<CaptionImage src="https://docs.juce.com/master/tutorial_simple_synth_noise_graph1.png" caption="A full scale ±1.0 sine wave." />


At a peak level of ±1.0 like this the output level will be *とても* loud. In fact, this is the loudest the audio system will be able to generate without clipping. Typically, we will need to output audio that doesn't exceed this ±1.0 limit (although it is fine for intermediate stages of processing to go beyond this limit, as long as the final output is lower).

## The AudioSampleBuffer class

While the AudioSampleBuffer class is (at a very basic level) just a multichannel array of `フロート` values, it provides a useful set of functions for dealing with audio data. Many of these functions will be covered in later tutorials, but here we make use of the following functions:

-   [AudioSampleBuffer::getNumChannels()](classAudioBuffer.html#a3a9ecde91bf5b96871ce3a474c1d831f "Returns the number of channels of audio data that this buffer contains."): This returns the number of audio channels stored in the buffer. In this case the value should match the number of output channels we requested in our call to the [AudioAppComponent::setAudioChannels()](classAudioAppComponent.html#a1cb6b457848fa80df7efc39cf095d465 "A subclass should call this from their constructor, to set up the audio.") function earlier. (This value will always be the maximum of the number of input and output channels.)
-   [AudioSampleBuffer::getWritePointer()](classAudioBuffer.html#a10cfe91eb4965895bc258cee02409d3b "Returns a writeable pointer to one of the buffer's channels."): This returns a pointer to the buffer of `フロート` values at a specific sample offset.

この単純なアプリケーションでホワイトノイズを生成するには、バッファの要求されたセクションをランダムな値で満たす必要があります。これを行うには、バッファ内のチャンネルを繰り返し処理し、そのチャンネルのバッファ内で開始サンプルを見つけ、必要なサンプル数をバッファに書き込みます：

```
void getNextAudioBlock (const juce::AudioSourceChannelInfo& bufferToFill) override
    {
        for (auto channel = 0; channel < bufferToFill.buffer->getNumChannels(); ++channel)
        {
            // この音声出力チャンネルのバッファ内の開始サンプルへのポインタを取得します。
            auto* buffer = bufferToFill.buffer->getWritePointer (channel, bufferToFill.startSample)；
 
            // 必要なサンプル数を-0.125から+0.125の間のノイズで埋める
            for (auto sample = 0; sample < bufferToFill.numSamples; ++sample)
                buffer[sample] = random.nextFloat() * 0.25f - 0.125f；
        }
    }
```

## Generating white noise using the Random class

Here we make use of the [ランダム](https://docs.juce.com/master/classRandom "A random number generator.") class in order to generate our random values (see [チュートリアルランダム・クラス](../tutorial_random/)). To generate white noise we need to generate uniformly distributed random numbers around zero. Here we generate random values between -0.125 and +0.125 by first calling the [ランダム::nextFloat()](classRandom.html#aec88d4e5cf44faaa038f6cfb41e96406 "Returns the next random floating-point number.") function. This generates values between 0 and 1. Then we multiply the result of this by 0.25 and subtract 0.125. (See [チュートリアルオーディオレベルのコントロール](../tutorial_synth_level_control/) for more information on this process.) Notice that we didn't use the [Random::getSystemRandom()](classRandom.html#ad7d9d42dd0efbb68d569e975b0778518 "The overhead of creating a new Random object is fairly small, but if you want to avoid it,...") function to get the shared *システム* [ランダム](https://docs.juce.com/master/classRandom "A random number generator.") object, as shown in other tutorials ([チュートリアルランダム・クラス](../tutorial_random/)). This is because we are calling the [ランダム::nextFloat()](classRandom.html#aec88d4e5cf44faaa038f6cfb41e96406 "Returns the next random floating-point number.") function on the audio thread. We need to create our own [ランダム](https://docs.juce.com/master/classRandom "A random number generator.") object otherwise the values might get corrupted by other threads using that shared [ランダム](https://docs.juce.com/master/classRandom "A random number generator.") object. To achieve this, an instance of the [ランダム](https://docs.juce.com/master/classRandom "A random number generator.") class is added to our `メインコンテンツコンポーネント` class:

```
プライベート：
    juce::Random random；
 
    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR (MainContentComponent).
};
```

## Shutting down the audio application

When our application is closed, our destructor will be called. At this point we should call the [AudioAppComponent::shutdownAudio()](classAudioAppComponent.html#a40f1e657f048d02c5d065de566a84d92 "Shuts down the audio device and clears the audio source.") function:

```
~MainContentComponent()オーバーライド
    {
        shutdownAudio()；
    }
```

Calling the [AudioAppComponent::shutdownAudio()](classAudioAppComponent.html#a40f1e657f048d02c5d065de566a84d92 "Shuts down the audio device and clears the audio source.") function will, in turn, cause the [AudioAppComponent::releaseResources()](classAudioAppComponent.html#a588d9b990fc308774215548959e0fc50 "Allows the source to release anything it no longer needs after playback has stopped.") function to be called. This is a good place to dispose of resources, if we allocated any during the running of our audio process (for example, if we allocated memory or opened some files). In this case, we didn't need any additional resources and we just log the function call with a simple message:

```
void releaseResources() override
    {
        juce::Logger::getCurrentLogger()->writeToLog ("Releasing audio resources")；
    }
```

オーディオ出力の数を変えてみてください。モノラルノイズはステレオノイズとは微妙に違って聞こえることに注意してください。マルチチャンネルのサウンドカードがあれば、2チャンネル以上のノイズを生成できるかもしれません。また、発生するノイズのレベルを変えてみることもできます。例えば、レベル0.1のノイズを生成するには、ランダムに生成された値に0.2を掛け、0.1を引く必要があります。

# 概要

This tutorial has introduced the [オーディオコンポーネント](https://docs.juce.com/master/classAudioAppComponent "A base class for writing audio apps that stream from the audio i/o devices.") class, used by the Audio Application template, in order to generate audio. We have covered the following topics:

-   オーディオシステムの初期化とシャットダウン。
-   オーディオ・コールバックに応答してオーディオ・データを書き込む。
-   Using the [オーディオソースチャンネル情報](https://docs.juce.com/master/structAudioSourceChannelInfo "Used by AudioSource::getNextAudioBlock().") struct and the AudioSampleBuffer class.

# 関連項目

-   [チュートリアルAudioDeviceManagerクラス](../tutorial_audio_device_manager/)
-   [チュートリアルサイン波シンセサイザーを作る](../tutorial_sine_synth/)
-   [チュートリアルデシベルを使ってオーディオレベルをコントロールする](../tutorial_synth_db_level_control/)
-   [チュートリアルオーディオレベルのコントロール](../tutorial_synth_level_control/)
-   [チュートリアルMIDIシンセサイザーを作る](../tutorial_synth_using_midi_input/)
-   [チュートリアルウェーブテーブルシンセシス](../tutorial_wavetable_synth/)