"use strict";(self.webpackChunkjuce_tutorial_ja=self.webpackChunkjuce_tutorial_ja||[]).push([[1957],{1157:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>h});var s=t(4848),i=t(8453),a=t(3449);t(6378);const r={title:"\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b",sidebar_position:5},o="\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b",l={id:"plugins/tutorial_plugin_examples",title:"\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b",description:"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa/\u30df\u30c7\u30a3\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b\u3092\u3044\u304f\u3064\u304b\u8a73\u3057\u304f\u8aac\u660e\u3057\u3001\u30d7\u30e9\u30b0\u30a4\u30f3\u958b\u767a\u306e\u30aa\u30fc\u30d7\u30f3\u306a\u53ef\u80fd\u6027\u3092\u63a2\u308a\u307e\u3059\u3002",source:"@site/docs/plugins/tutorial_plugin_examples.mdx",sourceDirName:"plugins",slug:"/plugins/tutorial_plugin_examples",permalink:"/juce-tutorial-ja/plugins/tutorial_plugin_examples",draft:!1,unlisted:!1,editUrl:"https://github.com/m1m0zzz/juce-tutorial-ja/tree/main/docs/plugins/tutorial_plugin_examples.mdx",tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"\u30ab\u30b9\u30b1\u30fc\u30c9\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3\u30fb\u30a8\u30d5\u30a7\u30af\u30c8",permalink:"/juce-tutorial-ja/plugins/tutorial_audio_processor_graph"},next:{title:"\u30a6\u30a7\u30fc\u30d6\u30c6\u30fc\u30d6\u30eb\u30fb\u30b7\u30f3\u30bb\u30b7\u30b9",permalink:"/juce-tutorial-ja/plugins/tutorial_new_projucer_project"}},c={},h=[{value:"Arpeggiator Implementation",id:"arpeggiator-implementation",level:2},{value:"Noise Gate Implementation",id:"noise-gate-implementation",level:2},{value:"Multi-Out Synth Implementation",id:"multi-out-synth-implementation",level:2},{value:"Surround Implementation",id:"surround-implementation",level:2}];function u(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b"}),"\n",(0,s.jsx)(n.p,{children:"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa/\u30df\u30c7\u30a3\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b\u3092\u3044\u304f\u3064\u304b\u8a73\u3057\u304f\u8aac\u660e\u3057\u3001\u30d7\u30e9\u30b0\u30a4\u30f3\u958b\u767a\u306e\u30aa\u30fc\u30d7\u30f3\u306a\u53ef\u80fd\u6027\u3092\u63a2\u308a\u307e\u3059\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u30ec\u30d9\u30eb Intermediate"}),"\n",(0,s.jsx)(n.p,{children:"\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0 Windows, macOS, Linux, iOS"}),"\n",(0,s.jsx)(n.p,{children:"\u30d7\u30e9\u30b0\u30a4\u30f3\u5f62\u5f0f\uff1a VST, VST3, AU, AAX, Standalone"}),"\n",(0,s.jsxs)(n.p,{children:["\u30af\u30e9\u30b9\uff1a ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiBuffer",title:"Holds a sequence of time-stamped midi events.",children:"\u30df\u30c7\u30a3\u30d0\u30c3\u30d5\u30a1"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSortedSet",title:"Holds a set of unique primitive objects, such as ints or doubles.",children:"\u30bd\u30fc\u30c8\u30bb\u30c3\u30c8"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioParameterFloat",title:"A subclass of AudioProcessorParameter that provides an easy way to create a parameter which maps onto...",children:"AudioParameterFloat"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiBuffer",title:"Holds a sequence of time-stamped midi events.",children:"\u30df\u30c7\u30a3\u30d0\u30c3\u30d5\u30a1"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiMessage",title:"Encapsulates a MIDI message.",children:"\u30df\u30c7\u30a3\u30e1\u30c3\u30bb\u30fc\u30b8"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioProcessorValueTreeState",title:"This class contains a ValueTree that is used to manage an AudioProcessor's entire state.",children:"\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30ed\u30bb\u30c3\u30b5\u5024\u30c4\u30ea\u30fc\u72b6\u614b"}),", ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classGenericAudioProcessorEditor",title:"A type of UI component that displays the parameters of an AudioProcessor as a simple list of sliders,...",children:"GenericAudioProcessorEditor (\u30b8\u30a7\u30cd\u30ea\u30c3\u30af\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30ed\u30bb\u30c3\u30b5\u30fc\u30a8\u30c7\u30a3\u30bf\u30fc)"})]}),"\n",(0,s.jsx)(n.h1,{id:"getting-started",children:"Getting started"}),"\n",(0,s.jsx)(n.p,{children:"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306b\u306f\u3044\u304f\u3064\u304b\u306e\u30c7\u30e2\u30fb\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u30fb\u30ea\u30f3\u30af\u306f\u3001\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u95a2\u9023\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u8a18\u8f09\u3055\u308c\u3066\u3044\u307e\u3059\u3002"}),"\n",(0,s.jsxs)(n.p,{children:["If you need help with this step in each of these sections, see ",(0,s.jsx)(n.a,{href:"../tutorial_new_projucer_project/",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30ebProjucer\u30d1\u30fc\u30c81\uff1aProjucer\u3092\u59cb\u3081\u308b"}),"."]}),"\n",(0,s.jsx)(n.h1,{id:"the-demo-projects",children:"The demo projects"}),"\n",(0,s.jsx)(n.p,{children:"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u63d0\u4f9b\u3055\u308c\u308b\u30c7\u30e2\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa/\u30df\u30c7\u30a3\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u3044\u304f\u3064\u304b\u306e\u7570\u306a\u308b\u4f8b\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\u8981\u7d04\u3059\u308b\u3068\u3001\u3053\u308c\u3089\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306f"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Creating interesting musical patterns with a simple arpeggiator. Jump to ",(0,s.jsx)(n.a,{href:"#tutorial_plugin_examples_arpeggiator",children:"\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Filtering out unwanted noises using a noise gate. Jump to ",(0,s.jsx)(n.a,{href:"#tutorial_plugin_examples_noise_gate",children:"\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Expanding the channel count to a multi-out synthesiser. Jump to ",(0,s.jsx)(n.a,{href:"#tutorial_plugin_examples_multi_out_synth",children:"\u30de\u30eb\u30c1\u30a2\u30a6\u30c8\u30fb\u30b7\u30f3\u30bb\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Expanding the channel count to a surround compatible plugin. Jump to ",(0,s.jsx)(n.a,{href:"#tutorial_plugin_examples_surround",children:"\u30b5\u30e9\u30a6\u30f3\u30c9\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["We use the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classGenericAudioProcessorEditor",title:"A type of UI component that displays the parameters of an AudioProcessor as a simple list of sliders,...",children:"GenericAudioProcessorEditor (\u30b8\u30a7\u30cd\u30ea\u30c3\u30af\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30ed\u30bb\u30c3\u30b5\u30fc\u30a8\u30c7\u30a3\u30bf\u30fc)"})," class common to all projects to lay out all of our GUI components across plugin examples."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["The code presented here is broadly similar to the ",(0,s.jsx)(n.strong,{children:"\u30d7\u30e9\u30b0\u30a4\u30f3\u30b5\u30f3\u30d7\u30eb"})," from the JUCE Examples."]})}),"\n",(0,s.jsx)(n.h1,{id:"the-arpeggiator-plugin",children:"The Arpeggiator Plugin"}),"\n",(0,s.jsxs)(n.p,{children:["Download the demo project for this section here: ",(0,s.jsx)(n.a,{href:"/tutorials/PIPs/ArpeggiatorTutorial.zip",children:"\u30d4\u30c3\u30d7"})," | ",(0,s.jsx)(n.a,{href:"/tutorials/ZIPs/ArpeggiatorTutorial.zip",children:"\u30b8\u30c3\u30d7"}),". Unzip the project and open the first header file in the Projucer."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:'Projucer\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u8a2d\u5b9a\u306e "Plugin Characteristics "\u30d5\u30a3\u30fc\u30eb\u30c9\u3067 "MIDI Effect Plugin "\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6709\u52b9\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002'})}),"\n",(0,s.jsx)(n.p,{children:"\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\u30fb\u30d7\u30ed\u30bb\u30c3\u30b7\u30f3\u30b0\u306e\u306a\u3044MIDI\u30d7\u30e9\u30b0\u30a4\u30f3\u3067\u3001\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30fb\u30a4\u30f3\u30b9\u30c8\u30a5\u30eb\u30e1\u30f3\u30c8\u3084DAW\u306eMIDI\u30c8\u30e9\u30c3\u30af\u306b\u633f\u5165\u3057\u3066\u3001\u5165\u529b\u3055\u308c\u308bMIDI\u4fe1\u53f7\u3092\u5909\u66f4\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002"}),"\n",(0,s.jsx)(a.A,{src:"https://docs.juce.com/master/tutorial_plugin_examples_arpeggiator_screenshot1.png",caption:"Arpeggiator plugin window"}),"\n",(0,s.jsx)(n.h2,{id:"arpeggiator-implementation",children:"Arpeggiator Implementation"}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc"})," class, we have defined several private member variables to implement our arpeggiator behaviour as shown below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"private:\n    //==============================================================================\n    juce::AudioParameterFloat* speed;\n    int currentNote, lastNoteValue;\n    int time;\n    float rate;\n    juce::SortedSet\u3068\u8a18\u3057\u3066\u3044\u308b\uff1b\n \n    //==============================================================================\n    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR (\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc)\n};\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Among these we have a ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSortedSet",title:"Holds a set of unique primitive objects, such as ints or doubles.",children:"\u30bd\u30fc\u30c8\u30bb\u30c3\u30c8"})," object that holds a set of unique int variables according to a certain sorting rule. This will allow us to reorder the MIDI notes efficiently to produce the desired musical patterns."]}),"\n",(0,s.jsx)(n.p,{children:"\u30af\u30e9\u30b9\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u3067\u306f\u3001MIDI\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u4f5c\u6210\u3059\u308b\u305f\u3081\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\u30d0\u30b9\u306a\u3057\u3067\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u3002\u307e\u305f\u3001\u3053\u3053\u306b\u793a\u3059\u3088\u3046\u306b\u3001\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc\u306e\u30b9\u30d4\u30fc\u30c9\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u30921\u3064\u8ffd\u52a0\u3057\u307e\u3059\uff1a"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc()\n        : AudioProcessor (BusesProperties()) // \u30aa\u30fc\u30c7\u30a3\u30aa\u30d0\u30b9\u3092\u5168\u304f\u8ffd\u52a0\u3057\u306a\u3044\n    {\n        addParameter (speed = new juce::AudioParameterFloat ("speed", "Arpeggiator Speed", 0.0, 1.0, 0.5))\uff1b\n    }\n'})}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"prepareToPlay()"})," function, we initialise some variables to prepare for subsequent processing like follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void prepareToPlay (double sampleRate, int) override\n    {\n        notes.clear();                          // [1]\n        currentNote = 0;                        // [2]\n        lastNoteValue = -1;                     // [3]\n        time = 0;                               // [4]\n        rate = static_cast(sampleRate); // [5].\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[1]: First, we empty the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSortedSet",title:"Holds a set of unique primitive objects, such as ints or doubles.",children:"\u30bd\u30fc\u30c8\u30bb\u30c3\u30c8"})," of MIDI note numbers."]}),"\n",(0,s.jsxs)(n.li,{children:["[2]: The currentNote variable temporarily holds the current index for the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSortedSet",title:"Holds a set of unique primitive objects, such as ints or doubles.",children:"\u30bd\u30fc\u30c8\u30bb\u30c3\u30c8"})," of notes."]}),"\n",(0,s.jsx)(n.li,{children:"[3]: The lastNoteValue variable temporarily holds the previous index to be able to stop the note."}),"\n",(0,s.jsx)(n.li,{children:"[4]: The time variable keeps track of the note duration with respect to the buffer size and sample rate."}),"\n",(0,s.jsx)(n.li,{children:"[5]: The rate stores the current sample rate in a float variable."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Next, we perform the actual processing in the ",(0,s.jsx)(n.code,{children:"processBlock()"})," function as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void processBlock (juce::AudioBuffer& buffer, juce::MidiBuffer& midi) override\n    {\n        // the audio buffer in a midi effect will have zero channels!\n        jassert (buffer.getNumChannels() == 0);                                                         // [6]\n \n        // however we use the buffer to get timing information\n        auto numSamples = buffer.getNumSamples();                                                       // [7]\n \n        // get note duration\n        auto noteDuration = static_cast(std::ceil (rate * 0.25f * (0.1f + (1.0f - (*\u901f\u5ea6))))); // [8].\n \n        for (const auto metadata : midi) // [9].\n        {\n            const auto msg = metadata.getMessage()\uff1b\n \n            if (msg.isNoteOn()) notes.add (msg.getNoteNumber())\uff1b\n            else if (msg.isNoteOff()) notes.removeValue (msg.getNoteNumber())\uff1b\n        }\n \n        midi.clear(); // [10].\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[6]: To ensure that we deal with a MIDI plugin, assert that there are no audio channels in the audio buffer."}),"\n",(0,s.jsx)(n.li,{children:"[7]: We still retrieve the number of samples in the block from the audio buffer."}),"\n",(0,s.jsx)(n.li,{children:"[8]: According to the speed parameter of our user interface and the sample rate, we calculate the note duration in number of samples."}),"\n",(0,s.jsxs)(n.li,{children:["[9]: For every event in the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiBuffer",title:"Holds a sequence of time-stamped midi events.",children:"\u30df\u30c7\u30a3\u30d0\u30c3\u30d5\u30a1"}),", we add the note to the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSortedSet",title:"Holds a set of unique primitive objects, such as ints or doubles.",children:"\u30bd\u30fc\u30c8\u30bb\u30c3\u30c8"}),' if the event is a "Note On" and remove the note if the event is a "Note Off".']}),"\n",(0,s.jsxs)(n.li,{children:["[10]: We then empty the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiBuffer",title:"Holds a sequence of time-stamped midi events.",children:"\u30df\u30c7\u30a3\u30d0\u30c3\u30d5\u30a1"})," to add the single notes back in the buffer one by one in the next step."]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"if ((time + numSamples) >= noteDuration) // [11].\n        {\n            auto offset = juce::jmax (0, juce::jmin ((int) (noteDuration - time), numSamples - 1)); // [12].\n \n            if (lastNoteValue > 0) // [13].\n            {\n                midi.addEvent (juce::MidiMessage::noteOff (1, lastNoteValue), offset)\uff1b\n                lastNoteValue = -1\uff1b\n            }\n \n            if (notes.size() > 0) // [14].\n            {\n                currentNote = (currentNote + 1) % notes.size()\uff1b\n                lastNoteValue = notes[currentNote]\uff1b\n                midi.addEvent (juce::MidiMessage::noteOn (1, lastNoteValue, (juce::uint8) 127), offset)\uff1b\n            }\n \n        }\n \n        time = (time + numSamples) % noteDuration; // [15].\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[11]: We check whether the current time with the number of samples in the current block added to it is greater than the note duration. If it is the case this means that by the end of the current block, we would reach a note transition and we therefore proceed to modify the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiBuffer",title:"Holds a sequence of time-stamped midi events.",children:"\u30df\u30c7\u30a3\u30d0\u30c3\u30d5\u30a1"}),". Otherwise we keep the MIDI state as is."]}),"\n",(0,s.jsx)(n.li,{children:"[12]: Calculate the sample offset at which the note transition occurs within the current audio block."}),"\n",(0,s.jsx)(n.li,{children:'[13]: If the previous note is still playing, the lastNoteValue variable is greater than 0 and therefore we need to send a "Note Off" event to stop the note from playing with the correct sample offset. We then reset the lastNoteValue variable.'}),"\n",(0,s.jsxs)(n.li,{children:["[14]: If there are notes to shuffle and play in the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSortedSet",title:"Holds a set of unique primitive objects, such as ints or doubles.",children:"\u30bd\u30fc\u30c8\u30bb\u30c3\u30c8"}),', we send a "Note On" event to play the first note in the set after having stored the previous note number and retrieved the next note number.']}),"\n",(0,s.jsx)(n.li,{children:"[15]: Finally we keep track of our current time relative to the note duration whether we reach a note transition or not."}),"\n"]}),"\n",(0,s.jsx)(n.h1,{id:"the-noise-gate-plugin",children:"The Noise Gate Plugin"}),"\n",(0,s.jsxs)(n.p,{children:["Download the demo project for this section here: ",(0,s.jsx)(n.a,{href:"/tutorials/PIPs/NoiseGateTutorial.zip",children:"\u30d4\u30c3\u30d7"})," | ",(0,s.jsx)(n.a,{href:"/tutorials/ZIPs/NoiseGateTutorial.zip",children:"\u30b8\u30c3\u30d7"}),". Unzip the project and open the first header file in the Projucer."]}),"\n",(0,s.jsx)(n.p,{children:"\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8\u306f\u3001DAW\u30c8\u30e9\u30c3\u30af\u306e\u30a4\u30f3\u30b5\u30fc\u30c8\u3068\u3057\u3066\u914d\u7f6e\u3055\u308c\u305f\u3068\u304d\u306b\u3001\u3042\u308b\u30b5\u30a4\u30c9\u30c1\u30a7\u30a4\u30f3\u30b9\u30ec\u30c3\u30b7\u30e7\u30eb\u30c9\u4ee5\u4e0b\u306e\u5165\u529b\u97f3\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30e9\u30b0\u30a4\u30f3\u3067\u3059\u3002"}),"\n",(0,s.jsx)(a.A,{src:"https://docs.juce.com/master/tutorial_plugin_examples_noise_gate_screenshot1.png",caption:"Noise gate plugin window"}),"\n",(0,s.jsx)(n.h2,{id:"noise-gate-implementation",children:"Noise Gate Implementation"}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8"})," class, we have defined several private member variables to implement our noise gate behaviour as shown below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\uff1a\n    //==============================================================================\n    juce::AudioParameterFloat* threshold\uff1b\n    juce::AudioParameterFloat* alpha\uff1b\n    int sampleCountDown\uff1b\n \n    float lowPassCoeff\uff1b\n \n    //==============================================================================\n    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR (NoiseGate)\n};\n"})}),"\n",(0,s.jsx)(n.p,{children:"In the class constructor, we initialise the plugin with three stereo buses for the input, output and sidechain respectively [1]. We also add two parameters namely threshold and alpha [2] as shown here:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8()\n        : AudioProcessor (BusesProperties().withInput ("Input", juce::AudioChannelSet::stereo()) // [1].\n                                           .withOutput ("Output", juce::AudioChannelSet::stereo())\n                                           .withInput ("Sidechain", juce::AudioChannelSet::stereo()))\n    {\n        addParameter (threshold = new juce::AudioParameterFloat ("threshold", "Threshold", 0.0f, 1.0f, 0.5f)); // [2].\n        addParameter (alpha = new juce::AudioParameterFloat ("alpha", "Alpha", 0.0f, 1.0f, 0.8f))\uff1b\n    }\n'})}),"\n",(0,s.jsx)(n.p,{children:"\u30b9\u30ec\u30c3\u30b7\u30e7\u30eb\u30c9\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306f\u3001\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8\u304c\u5165\u529b\u4fe1\u53f7\u306b\u4f5c\u7528\u3059\u308b\u30d1\u30ef\u30fc\u30ec\u30d9\u30eb\u3092\u6c7a\u5b9a\u3059\u308b\u3002alpha \u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306f\u3001\u30b5\u30a4\u30c9\u30c1\u30a7\u30a4\u30f3\u4fe1\u53f7\u306e\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002"}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"isBusesLayoutSupported()"})," function, we ensure that the number of input channels is identical to the number of output channels and that the input buses are enabled:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"bool isBusesLayoutSupported (const BusesLayout& layouts) const override\n    {\n        // \u30b5\u30a4\u30c9\u30c1\u30a7\u30fc\u30f3\u306f\u4efb\u610f\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u3092\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u304c\u3001\u30e1\u30a4\u30f3\u30d0\u30b9\u306f\u5165\u529b\u3068\u51fa\u529b\u3067\u540c\u3058\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002\n        return layouts.getMainInputChannelSet() == layouts.getMainOutputChannelSet()\n                 && ! layouts.getMainInputChannelSet().isDisabled()\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"prepareToPlay()"})," function, we initialise some variables to prepare for subsequent processing like follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"void prepareToPlay (double, int) override\n    {\n        lowPassCoeff = 0.0f; // [3].\n        sampleCountDown = 0; // [4].\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[3]: The low-pass coefficient will be calculated from the sidechain signal and the alpha parameter to determine the gating behaviour."}),"\n",(0,s.jsx)(n.li,{children:"[4]: The sample countdown allows us to keep track of the number of samples left with regards to the sample rate before the gating occurs."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Next, we perform the actual processing in the ",(0,s.jsx)(n.code,{children:"processBlock()"})," function as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void processBlock (juce::AudioBuffer& buffer, juce::MidiBuffer&) override\n    {\n        auto mainInputOutput = getBusBuffer (buffer, true, 0);                                  // [5]\n        auto sideChainInput  = getBusBuffer (buffer, true, 1);\n \n        auto alphaCopy = alpha->get();                                                          // [6]\n        auto thresholdCopy = threshold->get();\n \n        for (auto j = 0; j < buffer.getNumSamples(); ++j)                                       // [7]\n        {\n            auto mixedSamples = 0.0f;\n \n            for (auto i = 0; i < sideChainInput.getNumChannels(); ++i)                          // [8]\n                mixedSamples += sideChainInput.getReadPointer (i) [j];\n \n            mixedSamples /= static_cast(sideChainInput.getNumChannels())\uff1b\n            lowPassCoeff = (alphaCopy * lowPassCoeff) + ((1.0f - alphaCopy) * mixedSamples); // [9].\n \n            if (lowPassCoeff >= thresholdCopy) // [10].\n                sampleCountDown = (int) getSampleRate()\uff1b\n \n            // \u975e\u5e38\u306b\u52b9\u679c\u7684\u3067\u306a\u3044\u65b9\u6cd5\n            for (auto i = 0; i < mainInputOutput.getNumChannels(); ++i) // [11].\n                *mainInputOutput.getWritePointer (i, j) = sampleCountDown > 0 ?*mainInputOutput.getReadPointer (i, j)\n                                                                              : 0.0f;\n \n            if (sampleCountDown > 0) // [12].\n                -sampleCountDown\uff1b\n        }\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[5]: First, we separate the sidechain buffer from the main IO buffer for separate processing in subsequent steps."}),"\n",(0,s.jsx)(n.li,{children:"[6]: Then we retrieve copies of the threshold and alpha parameters."}),"\n",(0,s.jsx)(n.li,{children:"[7]: The outer loop will process the individual samples in the audio buffer block while the inner loops will process the channels in an interleaved manner. This allows us to keep the same state for each channel in a single sample processing."}),"\n",(0,s.jsx)(n.li,{children:"[8]: For each channel in the sidechain, we add the signals together and divide by the number of sidechain channels in order to sum the signal to mono."}),"\n",(0,s.jsx)(n.li,{children:"[9]: Next we calculate the low-pass coefficient from the alpha parameter and the sidechain mono signal using the formula y[i] = ((1 - alpha) * \u30b5\u30a4\u30c9\u30c1\u30a7\u30fc\u30f3) + (alpha * y[i - 1])."}),"\n",(0,s.jsx)(n.li,{children:"[10]: If this coefficient is greater than or equal to the threshold, we reset the sample countdown to the sample rate."}),"\n",(0,s.jsx)(n.li,{children:"[11]: For every input channel, we copy the input buffer sample to the output buffer if the countdown is non-zero. Otherwise, we mute the output signal by writing zero samples."}),"\n",(0,s.jsx)(n.li,{children:"[12]: We make sure to decrement the sample countdown value for every sample processed."}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"\u3053\u3053\u306b\u793a\u3057\u305f\u5b9f\u88c5\u306f\u3001\u901a\u5e38\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8\u3092\u30d7\u30ed\u30b0\u30e9\u30e0\u3059\u308b\u65b9\u6cd5\u3067\u306f\u306a\u3044\u3002\u4e16\u306e\u4e2d\u306b\u306f\u3082\u3063\u3068\u52b9\u7387\u7684\u3067\u512a\u308c\u305f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u3042\u308a\u307e\u3059\u3002"})}),"\n",(0,s.jsx)(n.h1,{id:"the-multi-out-synth-plugin",children:"The Multi-Out Synth Plugin"}),"\n",(0,s.jsxs)(n.p,{children:["Download the demo project for this section here: ",(0,s.jsx)(n.a,{href:"/tutorials/PIPs/MultiOutSynthTutorial.zip",children:"\u30d4\u30c3\u30d7"})," | ",(0,s.jsx)(n.a,{href:"/tutorials/ZIPs/MultiOutSynthTutorial.zip",children:"\u30b8\u30c3\u30d7"}),". Unzip the project and open the first header file in the Projucer."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:'Projucer\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u8a2d\u5b9a\u306e "Plugin Characteristics "\u30d5\u30a3\u30fc\u30eb\u30c9\u3067\u3001"Plugin MIDI Input "\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6709\u52b9\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002'})}),"\n",(0,s.jsx)(n.p,{children:"\u30de\u30eb\u30c1\u30a2\u30a6\u30c8\u30fb\u30b7\u30f3\u30bb\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\u30d5\u30a1\u30a4\u30eb\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u57fa\u306b\u6700\u59275\u3064\u306e\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc\u97f3\u8272\u3092\u751f\u6210\u3057\u3001\u6700\u592716\u306e\u30de\u30eb\u30c1\u51fa\u529b\u306b\u4fe1\u53f7\u3092\u51fa\u529b\u3059\u308b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30fb\u30a4\u30f3\u30b9\u30c8\u30a5\u30eb\u30e1\u30f3\u30c8\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3\u3067\u3059\u3002"}),"\n",(0,s.jsx)(a.A,{src:"https://docs.juce.com/master/tutorial_plugin_examples_multi_out_synth_screenshot1.png",caption:"Multi-out synth plugin window"}),"\n",(0,s.jsx)(n.h2,{id:"multi-out-synth-implementation",children:"Multi-Out Synth Implementation"}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"\u30de\u30eb\u30c1\u30a2\u30a6\u30c8\u30b7\u30f3\u30bb"})," class, we have defined several private member variables to implement our multi-out synth behaviour as shown below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    //==============================================================================\n    juce::AudioFormatManager formatManager;\n    juce::OwnedArraysynth\uff1b\n    juce::SynthesiserSound::Ptr sound\uff1b\n \n    //==============================================================================\n    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR (MultiOutSynth)\n};\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Among these we have an ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioFormatManager",title:"A class for keeping a list of available audio formats, and for deciding which one to use to open a gi...",children:"\u30aa\u30fc\u30c7\u30a3\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u30de\u30cd\u30fc\u30b8\u30e3\u30fc"})," in order to register audio file formats to read our sample sound. We also have an array of ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"})," objects that holds one synth per channel and a smart pointer to the sample sound we use in the tutorial."]}),"\n",(0,s.jsx)(n.p,{children:"\u307e\u305f\u3001MIDI\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u6700\u5927\u6570\u3084\u30b7\u30f3\u30bb\u306e\u30dc\u30a4\u30b9\u6570\u306e\u6700\u5927\u6570\u306a\u3069\u3001\u4fbf\u5229\u306a\u5b9a\u6570\u3082\u5ba3\u8a00\u3057\u3066\u3044\u308b\uff1a"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u5217\u6319\n    {\n        maxMidiChannel = 16\u3001\n        \u6700\u5927\u30dc\u30a4\u30b9\u6570 = 5\n    };\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In the class constructor, we initialise the plugin with 16 stereo output buses but no input bus [1] as we are creating a software instrument plugin. We also register basic audio file formats on the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioFormatManager",title:"A class for keeping a list of available audio formats, and for deciding which one to use to open a gi...",children:"\u30aa\u30fc\u30c7\u30a3\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u30de\u30cd\u30fc\u30b8\u30e3\u30fc"}),' object in order to read the ".ogg" sample file [2] as shown here:']}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'MultiOutSynth()\n        : AudioProcessor (BusesProperties())\n                          .withOutput ("Output #1", juce::AudioChannelSet::stereo(), true)\n                          .withOutput ("Output #2", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #3", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #4", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #5", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #6", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #7", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #8", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #9", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #10", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #11", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #12", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #13", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #14", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("Output #15", juce::AudioChannelSet::stereo(), false)\n                          .withOutput ("\u51fa\u529b #16", juce::AudioChannelSet::stereo(), false))   // [1]\n    {\n        // \u4ed6\u306e\u3082\u306e\u3092\u521d\u671f\u5316\u3059\u308b\uff08\u30d0\u30b9\u3068\u306f\u95a2\u4fc2\u306a\u3044\uff09\n        formatManager.registerBasicFormats(); // [2].\n \n        for (auto midiChannel = 0; midiChannel < maxMidiChannel; ++midiChannel) // [3].\n        {\n            synth.add (new juce::Synthesiser())\uff1b\n \n            for (auto i = 0; i < maxNumberOfVoices; ++i)\n                synth[midiChannel]->addVoice (new juce::SamplerVoice()); // [4].\n        }\n \n        loadNewSample (juce::MemoryBlock (singing_ogg, singing_oggSize)); // [5].\n    \n'})}),"\n",(0,s.jsxs)(n.p,{children:["For each midi/output channel, we instantiate a new ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"})," object, add it to the array [3] and create 5 ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSamplerVoice",title:"A subclass of SynthesiserVoice that can play a SamplerSound.",children:"\u30b5\u30f3\u30d7\u30e9\u30fc\u30dc\u30a4\u30b9"})," objects per synth [4]. We also load the sample file as binary data [5] using the ",(0,s.jsx)(n.code,{children:"loadNewSample()"})," private function defined hereafter:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'    void loadNewSample (const juce::MemoryBlock& sampleData)\n    {\n        auto soundBuffer = std::make_unique (sampleData, false);   // [6]\n        std::unique_ptrformatReader (formatManager.findFormatForFileExtension ("ogg")->createReaderFor (soundBuffer.release(), true))\uff1b\n \n        juce::BigInteger midiNotes\uff1b\n        midiNotes.setRange (0, 126, true)\uff1b\n        juce::SynthesiserSound::Ptr newSound = new juce::SamplerSound ("Voice", *formatReader, midiNotes, 0x40, 0.0, 0.0, 10.0); // [7].\n \n        for (auto channel = 0; channel < maxMidiChannel; ++channel) // [8].\n            synth[channel]->removeSound (0)\uff1b\n \n        sound = newSound; // [9] \u97f3\u3092\u524a\u9664\u3057\u307e\u3059\u3002\n \n        for (auto channel = 0; channel < maxMidiChannel; ++channel) // [10].\n            synth[channel]->addSound (sound)\uff1b\n    }\n'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[6]: First create a ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMemoryInputStream",title:"Allows a block of data to be accessed as a stream.",children:"\u30e1\u30e2\u30ea\u30fc\u5165\u529b\u30b9\u30c8\u30ea\u30fc\u30e0"}),' from the sample binary data and convert the stream to read the file as an "ogg" format.']}),"\n",(0,s.jsxs)(n.li,{children:["[7]: Declare a ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSamplerSound",title:"A subclass of SynthesiserSound that represents a sampled audio clip.",children:"\u30b5\u30f3\u30d7\u30e9\u30fc\u30b5\u30a6\u30f3\u30c9"})," object with the previously created stream reader and constrain the range of midi notes using a ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classBigInteger",title:"An arbitrarily large integer class.",children:"BigInteger"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["[8]: For every ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"})," object in the synth array, we make sure to clear the currently loaded ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiserSound",title:"Describes one of the sounds that a Synthesiser can play.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc\u30b5\u30a6\u30f3\u30c9"})," before loading a new one."]}),"\n",(0,s.jsxs)(n.li,{children:["[9]: Then assign the newly created ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSamplerSound",title:"A subclass of SynthesiserSound that represents a sampled audio clip.",children:"\u30b5\u30f3\u30d7\u30e9\u30fc\u30b5\u30a6\u30f3\u30c9"})," to the smart pointer to keep a reference to the sound."]}),"\n",(0,s.jsxs)(n.li,{children:["[10]: Finally, for every Synthesizer object we load the new sound as a ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSamplerSound",title:"A subclass of SynthesiserSound that represents a sampled audio clip.",children:"\u30b5\u30f3\u30d7\u30e9\u30fc\u30b5\u30a6\u30f3\u30c9"})," object."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["To make sure that no buses are added or removed beyond our requirements, we override two functions from the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioProcessor",title:"Base class for audio processing classes or plugins.",children:"\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30ed\u30bb\u30c3\u30b5"})," class as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"bool canAddBus (bool isInput) const override { return (! isInput && getBusCount (false) < maxMidiChannel); }.\n    bool canRemoveBus (bool isInput) const override { return (! isInput && getBusCount (false) > 1); }.\n"})}),"\n",(0,s.jsx)(n.p,{children:"\u3053\u308c\u306b\u3088\u308a\u3001\u30a4\u30f3\u30d7\u30c3\u30c8\u30d0\u30b9\u306e\u8ffd\u52a0\u3084\u524a\u9664\u3001\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u30d0\u30b9\u306e16\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u8d85\u3048\u308b\u8ffd\u52a0\u3084\u5b8c\u5168\u306a\u524a\u9664\u3092\u9632\u3050\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002"}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"prepareToPlay()"})," function, we prepare for subsequent processing by setting the sample rate for every ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"})," object in the synth array by calling the ",(0,s.jsx)(n.code,{children:"setCurrentPlaybackSampleRate()"})," function:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"void prepareToPlay (double newSampleRate, int samplesPerBlock) override\n    {\n        juce::ignoreUnused (samplesPerBlock)\uff1b\n \n        for (auto midiChannel = 0; midiChannel < maxMidiChannel; ++midiChannel)\n            synth[midiChannel]->setCurrentPlaybackSampleRate (newSampleRate)\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Next, we perform the actual processing in the ",(0,s.jsx)(n.code,{children:"processBlock()"})," function as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void processBlock (juce::AudioBuffer& buffer, juce::MidiBuffer& midiBuffer) \u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\n    {\n        auto busCount = getBusCount (false); // [11].\n \n        for (auto busNr = 0; busNr < busCount; ++busNr) // [12].\n        {\n            auto midiChannelBuffer = filterMidiMessagesForChannel (midiBuffer, busNr + 1)\uff1b\n            auto audioBusBuffer = getBusBuffer (buffer, false, busNr)\uff1b\n \n            synth [busNr]->renderNextBlock (audioBusBuffer, midiChannelBuffer, 0, audioBusBuffer.getNumSamples()); // [13].\n        }\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[11]: First, we retrieve the number of output buses."}),"\n",(0,s.jsxs)(n.li,{children:["[12]: For every output bus (and therefore for every ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"})," instance), we filter out the unnecessary audio bus buffers and filter out the midi messages that do not correspond to the midi channel of the synthesiser by calling a private helper function defined thereafter."]}),"\n",(0,s.jsxs)(n.li,{children:["[13]: We can then call the ",(0,s.jsx)(n.code,{children:"\u30ec\u30f3\u30c0\u30fc\u30cd\u30af\u30b9\u30c8\u30d6\u30ed\u30c3\u30af()"})," function directly on the corresponding ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classSynthesiser",title:"Base class for a musical device that can play sounds.",children:"\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc"})," object to generate the sound by supplying the correct audio bus buffer and midi channel buffer."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"MIDI\u30c1\u30e3\u30f3\u30cd\u30eb\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3059\u308b\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\uff1a"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"static juce::MidiBuffer filterMidiMessagesForChannel (const juce::MidiBuffer& input, int channel)\n    {\n        juce::MidiBuffer \u51fa\u529b\uff1b\n \n        for (auto metadata : input) // [14].\n        {\n            auto message = metadata.getMessage()\uff1b\n \n            if (message.getChannel() == channel)\n                output.addEvent (message, metadata.samplePosition)\uff1b\n        }\n \n        return output; // [15\uff3d\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["[14]: For every midi channel buffer, we check whether the midi message channel matches the midi channel of the output bus we are looking for and if so we add the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiMessage",title:"Encapsulates a MIDI message.",children:"\u30df\u30c7\u30a3\u30e1\u30c3\u30bb\u30fc\u30b8"})," to a newly-created ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classMidiBuffer",title:"Holds a sequence of time-stamped midi events.",children:"\u30df\u30c7\u30a3\u30d0\u30c3\u30d5\u30a1"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"[15]: When we have iterated over all midi messages in all midi channels, we return with a buffer containing only the midi messages of the selected channel."}),"\n"]}),"\n",(0,s.jsx)(n.h1,{id:"the-surround-plugin",children:"The Surround Plugin"}),"\n",(0,s.jsxs)(n.p,{children:["Download the demo project for this section here: ",(0,s.jsx)(n.a,{href:"/tutorials/PIPs/SurroundTutorial.zip",children:"\u30d4\u30c3\u30d7"})," | ",(0,s.jsx)(n.a,{href:"/tutorials/ZIPs/SurroundTutorial.zip",children:"\u30b8\u30c3\u30d7"}),". Unzip the project and open the first header file in the Projucer."]}),"\n",(0,s.jsx)(n.p,{children:"\u30b5\u30e9\u30a6\u30f3\u30c9\u30fb\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u306f\u3001\u30b5\u30e9\u30a6\u30f3\u30c9\u8a2d\u5b9a\u3092\u542b\u3080\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u5165\u529b\u4fe1\u53f7\u3092\u30e2\u30cb\u30bf\u30fc\u3057\u3001\u9078\u629e\u3057\u305f\u30c1\u30e3\u30f3\u30cd\u30eb\u306b\u30d4\u30f3\u306e\u30b5\u30a4\u30f3\u6ce2\u3092\u9001\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u30d7\u30e9\u30b0\u30a4\u30f3\u3067\u3059\u3002"}),"\n",(0,s.jsx)(a.A,{src:"https://docs.juce.com/master/tutorial_plugin_examples_surround_screenshot1.png",caption:"Surround plugin window"}),"\n",(0,s.jsx)(n.h2,{id:"surround-implementation",children:"Surround Implementation"}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"\u30b5\u30e9\u30a6\u30f3\u30c9\u30d7\u30ed\u30bb\u30c3\u30b5\u30fc"})," class, we have defined several private member variables to implement our surround behaviour as shown below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    juce::Array channelActive;\n    juce::ArrayalphaCoeffs\uff1b\n    int channelClicked\uff1b\n    int sampleOffset\uff1b\n \n    //==============================================================================\n    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR (SurroundProcessor)\n};\n"})}),"\n",(0,s.jsx)(n.p,{children:"\u3053\u308c\u3089\u306e\u3046\u3061\u3001\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u30a2\u30af\u30c6\u30a3\u30d6\u30fb\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u30b5\u30f3\u30d7\u30eb\u6570\u3092\u8a18\u9332\u3059\u308b\u914d\u5217\u3068\u3001\u5404\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u30a2\u30eb\u30d5\u30a1\u4fc2\u6570\u3092\u8a18\u9332\u3059\u308b\u914d\u5217\u304c\u3042\u308b\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u30af\u30e9\u30b9\u306e\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u3067\u306f\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u5165\u529b\u7528\u3068\u51fa\u529b\u7528\u306b\u305d\u308c\u305e\u308c2\u3064\u306e\u30b9\u30c6\u30ec\u30aa\u30fb\u30da\u30a2\u306e\u30d0\u30b9\u3067\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u304c\u3001\u69cb\u6210\u306f\u73fe\u5728\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u30d0\u30b9\u30fb\u30ec\u30a4\u30a2\u30a6\u30c8\u306e\u8a2d\u5b9a\u306b\u5fdc\u3058\u3066\u5909\u66f4\u3055\u308c\u307e\u3059\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'\u30b5\u30e9\u30a6\u30f3\u30c9\u30d7\u30ed\u30bb\u30c3\u30b5()\n        : AudioProcessor(BusesProperties().withInput ("Input", juce::AudioChannelSet::stereo())\n                                          .withOutput ("Output", juce::AudioChannelSet::stereo()))\n    {}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"isBusesLayoutSupported()"})," function, we ensure that the input/output channels are discrete channels [1], that the number of input channels is identical to the number of output channels [2] and that the input buses are enabled [3] as shown below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"bool isBusesLayoutSupported (const BusesLayout& layouts) const override\n    {\n        return ((! layouts.getMainInputChannelSet() .isDiscreteLayout()) // [1].\n             && (! layouts.getMainOutputChannelSet().isDiscreteLayout())\n             && (layouts.getMainInputChannelSet() == layouts.getMainOutputChannelSet()) // [2].\n             && (! layouts.getMainInputChannelSet().isDisabled()); // [3].\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.code,{children:"prepareToPlay()"})," function, we initialise some variables to prepare for subsequent processing like follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void prepareToPlay (double sampleRate, int samplesPerBlock) override\n    {\n        channelClicked = 0;                                             // [4]\n        sampleOffset = static_cast(std::ceil (sampleRate)); // [5].\n \n        auto numChannels = getChannelCountOfBus (true, 0); // [6].\n        channelActive.resize (numChannels)\uff1b\n        alphaCoeffs.resize (numChannels)\uff1b\n        reset(); // [7\uff3d\n \n        triggerAsyncUpdate(); // [8].\n \n        juce::ignoreUnused (samplesPerBlock)\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[4]: First, we reset the temporary variable that designates the channel index that is clicked by the user."}),"\n",(0,s.jsx)(n.li,{children:"[5]: Then we store the sample rate before processing the block and later on incrementing this temporary variable to keep track of phase with sample offsets."}),"\n",(0,s.jsx)(n.li,{children:"[6]: We need to resize the active channels and coefficients arrays to the currently active number of channels for the block."}),"\n",(0,s.jsxs)(n.li,{children:["[7]: The ",(0,s.jsx)(n.code,{children:"\u30ea\u30bb\u30c3\u30c8"})," function is called at several places to clear the active channels array as defined later."]}),"\n",(0,s.jsx)(n.li,{children:"[8]: Finally, we trigger an asynchronous update to the GUI thread and handle the callback later on."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"\u30ea\u30bb\u30c3\u30c8"})," function is also called in the ",(0,s.jsx)(n.code,{children:"releaseResources()"})," function after the block processing finishes:"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"\u30ea\u30bb\u30c3\u30c8"})," function is implemented by setting every channel value to 0 like follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"void reset() \u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\n    {\n        for (auto& channel : channelActive)\n            channel = 0\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["As for the asynchronous update of the GUI, we handle the callback by calling the ",(0,s.jsx)(n.code,{children:"updateGUI()"})," function on the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioProcessorEditor",title:"Base class for the component that acts as the GUI for an AudioProcessor.",children:"\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30ed\u30bb\u30c3\u30b5\u30fc\u30a8\u30c7\u30a3\u30bf\u30fc"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void handleAsyncUpdate() override\n    {\n        if (auto* editor = getActiveEditor())\n            if (auto* surroundEditor = dynamic_cast(\u30a8\u30c7\u30a3\u30bf))\n                surroundEditor->updateGUI()\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Since the ",(0,s.jsx)(n.a,{href:"https://docs.juce.com/master/classAudioProcessor",title:"Base class for audio processing classes or plugins.",children:"\u30aa\u30fc\u30c7\u30a3\u30aa\u30d7\u30ed\u30bb\u30c3\u30b5"})," inherits from the ChannelClickListener class defined in the ",(0,s.jsx)(n.code,{children:"\u30b5\u30e9\u30a6\u30f3\u30c9\u30a8\u30c7\u30a3\u30bf\u30fc"})," class, we have to override its virtual functions. The ",(0,s.jsx)(n.code,{children:"channelButtonClicked()"})," callback function is triggered when the user clicks on a channel button. It provides the channel index that was pressed and resets the sample offset variable like so:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"void channelButtonClicked (int channelIndex) override\n    {\n        channelClicked = channelIndex\uff1b\n        sampleOffset = 0\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"isChannelActive()"})," helper function returns whether the specified channel is active by checking whether the active channel array still has samples to process:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u30d6\u30fc\u30eb isChannelActive (int channelIndex) \u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\n    {\n        return channelActive[channelIndex] > 0\uff1b\n    }\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Next, we perform the actual processing in the ",(0,s.jsx)(n.code,{children:"processBlock()"})," function as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"    void processBlock (juce::AudioBuffer& buffer, juce::MidiBuffer&) override\n    {\n        for (auto ch = 0; ch < buffer.getNumChannels(); ++ch)                   // [9]\n        {\n            auto& channelTime = channelActive.getReference (ch);\n            auto& alpha = alphaCoeffs.getReference (ch);\n \n            for (auto j = 0; j < buffer.getNumSamples(); ++j)                   // [10]\n            {\n                auto sample = buffer.getReadPointer (ch)[j];\n                alpha = (0.8f * alpha) + (0.2f * sample);\n \n                if (std::abs (alpha) >= 0.1f)                                   // [11]\n                    channelTime = static_cast(getSampleRate() / 2.0)\uff1b\n            }\n \n            channelTime = juce::jmax (0, channelTime - buffer.getNumSamples()); // [12].\n        }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[9]: For each channel in the audio buffer, we get a reference to the active channel countdown samples and the alpha coefficient values."}),"\n",(0,s.jsx)(n.li,{children:"[10]: Then for every sample in the buffer block, we get the input sample value of the channel and calculate the alpha coefficient using the formula alpha[i] = ((1 - x) * \u30b5\u30f3\u30d7\u30eb) + (x * alpha[i - 1]) where x = 0.8 in this case."}),"\n",(0,s.jsx)(n.li,{children:"[11]: If the alpha coefficient is greater than or equals to a certain threshold in this case 0.1, we set the countdown samples for that specific channel to half of the sample rate."}),"\n",(0,s.jsx)(n.li,{children:"[12]: We also make sure to subtract the number of samples in the current block from the number of samples in the countdown."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"        auto fillSamples = juce::jmin (static_cast (std::ceil (getSampleRate())) - sampleOffset,\n                                       buffer.getNumSamples());                 // [13]\n \n        if (juce::isPositiveAndBelow (channelClicked, buffer.getNumChannels())) // [14]\n        {\n            auto* channelBuffer = buffer.getWritePointer (channelClicked);\n            auto freq = (float) (440.0 / getSampleRate());\n \n            for (auto i = 0; i < fillSamples; ++i)                              // [15]\n                channelBuffer[i] += std::sin (2.0f * juce::MathConstants::pi * freq * static_cast(sampleOffset++))\uff1b\n        }\n    }\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"[13]: Next we calculate the number of output samples to fill by taking the smallest number of the two from the sample offset and the number of samples in the block."}),"\n",(0,s.jsx)(n.li,{children:"[14]: Then we can check whether the channel index clicked is valid and get the write pointer for the correct channel buffer."}),"\n",(0,s.jsx)(n.li,{children:"[15]: Finally we calculate the frequency of the sine wave by dividing the A4 frequency by the sample rate. Then for every sample to fill, we produce a sine wave with appropriate frequency and phase offset using the sample offset variable that we increment after the assignment for the next sample."}),"\n"]}),"\n",(0,s.jsx)(n.h1,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u306f\u3001\u30aa\u30fc\u30c7\u30a3\u30aa\uff0f\u30df\u30c7\u30a3\u30fb\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4f8b\u3092\u3044\u304f\u3064\u304b\u898b\u3066\u304d\u307e\u3057\u305f\u3002\u7279\u306b"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u30b7\u30f3\u30d7\u30eb\u306a\u30a2\u30eb\u30da\u30b8\u30a8\u30fc\u30bf\u30fc\u3092\u4f5c\u308a\u3001\u9762\u767d\u3044\u97f3\u697d\u30d1\u30bf\u30fc\u30f3\u3092\u4f5c\u308b\u3002"}),"\n",(0,s.jsx)(n.li,{children:"\u4e0d\u8981\u306a\u30ce\u30a4\u30ba\u3092\u9664\u53bb\u3059\u308b\u30ce\u30a4\u30ba\u30b2\u30fc\u30c8\u3092\u5185\u8535\u3002"}),"\n",(0,s.jsx)(n.li,{children:"\u8907\u6570\u306e\u51fa\u529b\u3092\u6301\u3064\u30b7\u30f3\u30bb\u30b5\u30a4\u30b6\u30fc\u3092\u88fd\u4f5c\u3002"}),"\n",(0,s.jsx)(n.li,{children:"\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u3092\u62e1\u5f35\u3059\u308b\u305f\u3081\u306b\u30b5\u30e9\u30a6\u30f3\u30c9\u5bfe\u5fdc\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u69cb\u7bc9\u3002"}),"\n"]}),"\n",(0,s.jsx)(n.h1,{id:"see-also",children:"See also"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"../tutorial_create_projucer_basic_plugin/",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u57fa\u672c\u7684\u306aAudio/MIDI\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u4f5c\u308b, \u30d1\u30fc\u30c81\uff1a\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"../tutorial_code_basic_plugin/",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u57fa\u672c\u7684\u306aAudio/MIDI\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u4f5c\u308b, \u30d1\u30fc\u30c82: \u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"../tutorial_midi_message/",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30ebMIDI\u30c7\u30fc\u30bf\u306e\u4f5c\u6210"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"../tutorial_handling_midi_events/",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\uff1aMIDI\u30a4\u30d9\u30f3\u30c8\u306e\u51e6\u7406"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"../tutorial_audio_processor_graph/",children:"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u30ab\u30b9\u30b1\u30fc\u30c9\u30d7\u30e9\u30b0\u30a4\u30f3\u30a8\u30d5\u30a7\u30af\u30c8"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},3449:(e,n,t)=>{t.d(n,{A:()=>i});var s=t(4848);function i(e){let{src:n,caption:t,alt:i,width:a,height:r}=e;return(0,s.jsxs)("figure",{children:[(0,s.jsx)("img",{src:n,alt:i||t,width:a,height:r}),(0,s.jsx)("figcaption",{children:(0,s.jsx)("b",{children:t})})]})}},6378:(e,n,t)=>{t.d(n,{A:()=>i});var s=t(4848);function i(e){let{path:n}=e;return(0,s.jsx)("p",{children:(0,s.jsx)("a",{href:"https://docs.juce.com/master/"+n,children:"\ud83d\udcda Source Page"})})}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(6540);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);